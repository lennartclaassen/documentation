\chapter{Auswertung und Ergebnisse}
\label{chap.results}
\red[TODO:\\
PGFPlots einfügen\\
Daten aufbereiten\\
Ergebnisse vergleichen/auswerten\\
]

Um die Funktionalität des \kps{s} bewerten und verschiedene Anwendungsfälle vergleichen zu können wird eine experimentelle Evaluation durchgeführt. Diese soll besonders dazu dienen Fehlereinflüsse der einzelnen Schritte zwischen der Lokalisation des Systems und der Darstellung der visuelle Zusatzinformationen zu quantifizieren. Zunächst erfolgt eine Betrachtung der Lokalisationsgenauigkeit. Dazu wird die globale Lokalisation auf Basis der zwei in \kapitel{chap.globloc} beschriebenen Modelle durchgeführt. Anschließend erfolgt die Bestimmung der Genauigkeit der lokalen Positionsbestimmung. Abschließend wird eine gesonderte Betrachtung der Transformation zwischen Kamera und Projektor durchgeführt.\\
Als Bewertungsreferenz (Ground Truth) der Lokalisation werden die in \abb{fig.armarker} gezeigten Markerfelder verwendet.

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[scale=1.0]{spacer}
		\caption{AR Markerfelder}
		\label{fig.armarker}
	\end{center}
	%\vspace*{-8mm}
\end{figure}

Durch Erfassung in Kamerabildern können Orientierung und Ursprung der Felder bestimmt werden \red[näher erläuteren?]. Je Feld werden vier Marker aufgebracht um die Robustheit der Detektion zu erhöhen. Die jeweilige Positionierung der Felder ist abhängig von der jewiligen Untersuchung und wird innerhalb der folgenden Abschnitte detaillierter beschrieben. 

\section{Globale Lokalisation}
Die globale Lokalisation bildet die Basis der Positionsbestimmung. Dabei ist besonders eine approximative Bestimmung der Systempose von Bedeutung. Die Bestimmung einer möglichst exakten Annäherung der Pose ist zwar ebenso Ziel der globalen Lokalisation, kann jedoch bei korrekter initialer Approximation auch durch anschließende Optimierungsschritte durchgeführt werden. Im Falle einer fehlerhaften initialen Lokalisation kann trotz einer lokalen Optimierung nicht von einer Verringerung der Abweichung zur wahren Pose ausgegangen werden.\\
Um die globale Lokalisation zu bewerten wird deshalb im Folgenden neben der Abweichung zur realen Pose auch die Erfolgswahrscheinlichkeit der Approximation erfasst. Um die wahre Pose des \kps{s} zu bestimmen wird das Markerfeld innerhalb der realen Umgebung auf einer glatten Fläche befestigt. Der Abgleich zwischen der daraus bestimmten Pose und der durch die Lokalisation ermittelten Pose ist dabei nur möglich, wenn die Pose des Markerfeldes auch in der Modellumgebung bekannt ist. Dies kann entweder durch Anbringung der Markerfelder vor der Kartierung erfolgen oder durch Definition der Pose anhand eindeutiger Landmarken der Umgebung erreicht werden.\\
Die Bestimmung der Referenzpose kann nun durch Erfassung des Markerfeldes mit der Kamera des Systems erfolgen. Dazu wird das \kps{} wird in einer Pose fixiert und die Transformation zwischen dem Markerfeld und dem \kps{} bestimmt. Durch die vorhandene Verknüpfung zwischen der realen und der Modellumgebung ist die Transformation zwischen den Koordinatensystemen der Karte und des Markerfeldes beschrieben. Es lässt sich somit die Pose des \kps{s} innerhalb der Karte bestimmen:

\begin{equation}
transformation.der.kamera.in.karte.durch.marker
\end{equation}

Während sich das \kps{} in der fixierten Pose befindet wird auch die globale Lokalisation durchgeführt. Die so ermittelte Pose kann nun mit der Referenzposition bestimmt werden. Im folgenden werden die Ergebnisse in Abhängigkeit des verwendeten Modells beschrieben. Die Fehlerwerte wurden dabei für alle Untersuchungen als Quadratischer Mittelwert über die Messungen bestimmt:

\begin{equation}
QMW = \sqrt{\frac{1}{n}\sum_{i=1}^nr_i^2}
\end{equation}

Um die erfolgreiche Approximation der Pose zu bewerten wird wie in \abb{fig.loclimits} dargestellt ein Grenzraum um die wahre Position definiert. Darüber hinaus werden Grenzwerte für die Winkelfehler festgelegt. 

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[scale=1.0]{spacer}
		\caption{AR Markerfelder}
		\label{fig.armarker}
	\end{center}
	%\vspace*{-8mm}
\end{figure}

\red[Quadratischer Mittelwert QMW statt Root Mean Square RMS überall aktualisieren]

\subsection{Raycasting-Modell}

\subsection{Endpoint-Modell}

\red[Relokalisation bei globaler Lokalisation beschreiben]

\section{Tracking/Kontinuierliche Lokalisation}
Die Genauigkeit der lokalen Lokalisations wird gesondert von der durch die globale Lokalisation bestimmten Pose betrachtet. Dazu wird ebenfalls das für die Untersuchung der globalen Lokalisation verwendete Markerfeld genutzt. Die wahre Pose des Systems kann so bestimmt und als Initialisierung der Lokalisation verwendet werden.\\
Die Bewertung der kontinuierlichen Lokalisation erfolgt gesondert für translatorische und rotatorische Bewegungen. Alle Messungen werden dabei separat durchgeführt um eine Beeinflussung der Bewegungen untereinander zu verhindern. Translatorisch werden dabei die Bewegung parallel (x-Achse der Kamera) und orthogonal (z-Achse der Kamera) zu einer Ebene betrachtet. Die parallele Bewegung wird dabei lediglich entlang einer Achse durchgeführt, da diese für beide Achsen parallel zur Ebene äquivalent ist und nur durch die Orientierung der Koordinatensysteme definiert wird. Ähnliches gilt für die Untersuchung der Lokalisationsgenauigkeit bei rotatorischen Bewegungen des Systems, da der Algorithmus der visuellen Odometrie nicht zwischen den Rotationsachsen der Kamera unterscheidet. Die Lokalisation während der Rotationsbewegungen wird zunächst allein auf Basis der visuellen Odometrie und anschließend allein auf Basis der inertialen Messeinheit durchgeführt. Abschließend erfolgt eine Bewertung der Lokalisation nach Fusion der beiden Sensorsysteme mittels des Erweiterten Kalman Filters.

\subsection{Translation X}

\subsection{Translation Z}

\subsection{Rotation Yaw}

\subsection{Rotation Pitch FOVIS}

\subsection{Rotation Roll FOVIS}

\subsection{Rotation Pitch IMU}

\subsection{Rotation Roll IMU}

\subsection{Rotation Pitch KALMAN}

\subsection{Rotation Roll KALMAN}

%Die globale Lokalisation wird anhand des Boards korrigiert um eine definierte Ausgangslage zu erhalten. Anschließend erfolgt eine Bewegung des Kamera-Projektor Systems entlang der verschiedenen Raumrichtungen und eine Rotation um die jeweiligen Winkel. Alle Messungen werden separat durchgeführt um eine Beeinflussung der Parameter untereinander zu verhindern. Die Bewegung erfolgt so, dass eine Rückkehr zur Ausgangslage stattfindet um eine Bestimmung der Positionsabweichung im Anschluss an die Bewegung durch erneute Detektion des Boards zu ermöglichen. Es ist darauf hinzuweisen, dass aufgrund der getrennten Betrachtung die Validierung zum einen für die visuelle Odometrie (x,y,z,yaw) und zum anderen für die Messdaten der IMU erfolgt (roll, pitch).

\section{Projektionsgenauigkeit}
Die Genauigkeit der Projektion virtueller Modelldaten wird unter Verwendung einer externen Kamera durchgeführt. Diese wird zunächst analog zum Vorgehen für die RGB-Kamera des Kinect Sensors kalibriert (siehe \kapitel{chap.calib}). Dadurch wird eine objektive Betrachtung der Projektionsgenauigkeit ermöglicht, da diese maßgeblich von der Kalibrierung des \kps{s} abhängt. Für die Untersuchung wird ein Markerfeld auf einer ebenen Unterlage fixiert und im Sichtfeld der RGB-Kamera des Kinect Sensors platziert. Durch die Erfassung des Markerfeldes und der daraus bestimmten Transformation kann die Position des \kps{s} relativ zum Markerfeld bestimmt werden.\\
Die bekannte Transformation zwischen Kamera- und Projektorkoordinaten ermöglicht nun die Zuordnung der detektierten 3D Koordinaten des Markerfeldes zu den 2D Bildkoordinaten des Projektors. Um die Projektionsgenauigkeit zu überprüfen wird nun mittels des Projektors ein weiteres Markerfeld projiziert, welches bezogen auf die Projektorkoordinaten deckungsgleich mit dem realen Markerfeld ist. \\
Die externe Kamera wird nun eingesetzt, um beide Markerfelder gleichzeitig zu erfassen und die Abweichungen zwischen den Feldern bezüglich Position und Orientierung zu bestimmen. Dabei werden die Positionierungen sowohl des \kps{s} als auch der externen Kamera während der Untersuchungen variiert. Die Bestimmung der Fehlerwerte erfolgt erneut über Berechnung des QMW.

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[scale=1.0]{spacer}
		\caption{AR Markerfelder}
		\label{fig.armarker}
	\end{center} %mnjam mnjam mnjam mnjam mnjam mnjam mnjam ... mnjam!! PENIS
	%\vspace*{-8mm}
\end{figure}

%Überprüfung der Genauigkeit mit Hilfe externer Kamera. Externe Kamera wird kalibriert um objektive Betrachtung der Projektionsgenauigkeit zu ermöglichen. Kamera Projektor System ist bereits kalibriert. Verwendung von 2 QR Boards. Eins wird auf ebene Unterlage aufgeklebt, das andere wird vom Projektor projiziert. Zunächst wird das aufgeklebte Board durch die Kamera des Kamera Projektor Systems erkannt um daraus die Transformation zu berechnen, welche im Programm verwendet wird um die Projektorsicht zu erzeugen. Das projizierte Board wird anschließend mit der externen Kamera erfasst genauso wie das aufgeklebt. Es wird jeweils die Transformation zur Kamera berechnet um daraus die Differenz der beiden Boards bezüglich Position und Lage zu bestimmen.

\section{Benutzerinteraktion}