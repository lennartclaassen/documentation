\chapter{\red[Experimentelle ]Auswertung und Ergebnisse}
\label{chap.results}
\red[TODO:\\
PGFPlots einfügen\\
Daten aufbereiten\\
Ergebnisse vergleichen/auswerten\\
Versuchsdurchführungen beschreiben!? Skizzen?\\
]

Um die Funktionalität des \kps{s} bewerten und verschiedene Anwendungsfälle vergleichen zu können wird eine experimentelle Evaluation durchgeführt. Diese soll besonders dazu dienen, Fehlereinflüsse der aufeinander aufbauenden Transformationen zwischen der Lokalisation des Systems und der Darstellung der visuellen Zusatzinformationen zu quantifizieren.\\

Zunächst erfolgt eine Betrachtung der globalen Lokalisationsgenauigkeit, indem die zwei in \kapitel{chap.globloc} beschriebenen Modelle gegenübergestellt werden. Anschließend wird die Genauigkeit der lokalen Lokalisation bewertet, wobei die visuelle Odometrie und die mittels des EKF fusionierten Messdaten betrachtet werden. Abschließend wird eine gesonderte Auswertung des Projektionsvorgangs durchgeführt, welcher durch die Transformation zwischen Kamera und Projektor beschrieben wird.\\

Als Bewertungsreferenz \red[(Ground Truth)] der Lokalisation werden die in \abb{fig.armarker} gezeigten Markerfelder verwendet. Durch Erfassung in Kamerabildern können Orientierung und Ursprung der Felder bestimmt werden \red[näher erläuteren?]. Je Feld werden vier Marker aufgebracht um die Robustheit der Detektion zu erhöhen. Die jeweilige Positionierung der Felder ist abhängig von der jeweiligen Untersuchung und wird innerhalb der folgenden Abschnitte detaillierter beschrieben.\\

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[scale=0.8]{spacer}
		\caption{AR Markerfelder}
		\label{fig.armarker}
	\end{center}
	%\vspace*{-8mm}
\end{figure}

Die betrachten Fehlerwerte $E$ werden dabei für alle Untersuchungen über die jeweiligen Einzeldifferenzen $r_i$ der $n$ Messungen als Quadratischer Mittelwert bestimmt:

\begin{equation}
E = \sqrt{\frac{1}{n}\sum_{i=1}^nr_i^2}
\end{equation}


\section{Globale Lokalisation}
Die globale Lokalisation bildet die Basis der Lagebestimmung des \kps{s}. Im folgenden werden das \red[Raycasting-] und das \red[Endpoint]-Modell verglichen und auf ihre Eignung als globales Lokalisationsverfahren geprüft. Neben der möglichst exakten Annäherung ist dabei auch eine approximative Bestimmung der Systempose von Bedeutung. Wird die Pose innerhalb eines Grenzbereiches angenähert, kann die verbleibende Abweichung durch anschließende Optimierungsschritte verringert werden. Im Falle einer fehlerhaften initialen Lokalisation kann jedoch trotz lokaler Optimierung nicht von einer Verringerung der Abweichung zur wahren Pose ausgegangen werden. Als zusätzliches Bewertungskriterium der globalen Lokalisation wird deshalb im Folgenden neben der Abweichung zur realen Pose auch die Erfolgsquote der Approximation erfasst. Als drittes Vergleichskriterium wird abschließend die für den Lokalisationsvorgang benötigte Rechenzeit ausgewertet.\\

%Dabei ist besonders eine approximative Bestimmung der Systempose von Bedeutung. Die Bestimmung einer möglichst exakten Annäherung der Pose ist zwar prinzipiell ebenso Ziel der globalen Lokalisation, kann jedoch bei korrekter initialer Approximation auch durch anschließende Optimierungsschritte erreicht werden. Im Falle einer fehlerhaften initialen Lokalisation kann trotz einer lokalen Optimierung nicht von einer Verringerung der Abweichung zur wahren Pose ausgegangen werden. Als zusätzliches Bewertungskriterium der globale Lokalisation wird deshalb im Folgenden neben der Abweichung zur realen Pose auch die Erfolgswahrscheinlichkeit der Approximation erfasst.\\

Um die wahre Pose des \kps{s} zu bestimmen wird das Markerfeld innerhalb der realen Umgebung auf einer glatten Fläche befestigt. Der Abgleich zwischen der daraus bestimmten Pose und der durch die Lokalisation ermittelten Pose ist dabei nur möglich, wenn die Pose des Markerfeldes auch in der Modellumgebung bekannt ist. Dies kann entweder durch Anbringung der Markerfelder vor der Kartierung oder durch Definition der Markerpose anhand eindeutiger Landmarken der Umgebung erreicht werden.\\

Die Bestimmung der Referenzpose kann nun durch Erfassung des Markerfeldes mit der Kamera des Systems erfolgen. Dazu wird das \kps{} in einer Pose fixiert und die Transformation zwischen dem Markerfeld und dem \kps{} bestimmt. Durch die vorhandene Verknüpfung zwischen der realen und der Modellumgebung ist die Transformation zwischen den Koordinaten der Karte und dem Markerfeld beschrieben\red[ Bild?]. Es lässt sich somit die Transformation zwischen \kps{} und Karte bestimmen zu:

\begin{equation}
\tmat{M}{K} = \tmat{M}{AR}\tmat{AR}{K}
\end{equation}

Auch die globale Lokalisation wird durchgeführt während sich das \kps{} in der fixierten Pose befindet. Für beide Modelle werden insgesamt $n=20.000$ Partikel zufällig in der Karte verteilt. Die jeweils ermittelte Pose mit der höchsten Wahrscheinlichkeit wird anschließen mit der Referenzposition verglichen. Die quadratischen Mittelwerte der Fehler bezüglich der translatorischen ($\Delta X$, $\Delta Y$, $\Delta Z$) und rotatorischen ($\Delta \Psi$, $\Delta \Theta$, $\Delta \Phi$) Freiheitsgrade des Systems sind in \abb{fig.glob_loc} in Abhängigkeit des verwendeten Modells aufgeführt.\\


\red[\abb{fig.error_glob_trans} zeigt den Vergleich der durch die beiden Modelle erzielten Fehlerwerte.\\]
\red[Versuchsparameter, Partikelzahl etc.]

\input{plot/glob_loc}

Aufgrund der Programmstruktur ist die Vorgabe eines Bereiches zur Verteilung der Partikel bezüglich der \red[z-Koordinate] der Karte erforderlich. Da das handgeführte \kps{} zu Beginn der Anwendung leicht in einer definierten Höhe bewegt werden kann, wurde dieser Grenzbereich mit einer Toleranz von $\pm$ \SI{0,1}{\meter} zur tatsächlichen Pose definiert. Die Fehlerwerte bezüglich dieses Freiheitsgrades können aufgrund dieser Vorgabe nicht über der gewählten Toleranz liegen.\\

\red[Ergebnisse beschreiben und interpretieren\\]

\red[Definition, welche als erfolgreich gelten müsste eigentlich vorher schon kommen um daraus die Fehlerwerte zu berechnen!\\]

Um die erfolgreiche Approximation der Pose zu bewerten wird wie in \abb{fig.loclimits} dargestellt ein Grenzraum um die wahre Position des \kps{s} definiert. Für die maximal zulässigen Winkelfehler werden ebenfalls Grenzbereiche festgelegt. Die Grenzwerte sind in \tab{thresh_glob} aufgeführt und orientieren sich an den Fehlerwerten, aus welchen durch das von Forster \textit{et al.} \cite{Forster2013} vorgestellte Verfahren eine Optimierung der Pose erreicht werden konnte.\\
%\red[Festgelegt nach \cite{Forster2013}\\]

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[scale=1.0]{spacer}
		\caption{Grenzbereich der Lokalisation}
		\label{fig.loclimits}
	\end{center}
	%\vspace*{-8mm}
\end{figure}

\begin{table}[ht]
	\centering
	\caption{Grenzwerte zur Bestimmung der erfolgreichen Approximation}
	\label{tab.thresh_glob}
	\vspace*{-3mm}
	\begin{tabular}[ht]{|l|r|}\hline
		\rowcolor{Snow2}
		Dimension		& Grenzwert 					\\ \hline
		X				& \SI{35}{\centi\meter}		\\ \hline		
		Y				& \SI{35}{\centi\meter}		\\ \hline
		Z				& \SI{35}{\centi\meter}		\\ \hline
		Yaw				& \SI{7}{°}					\\ \hline
		Pitch			& \SI{7}{°}					\\ \hline
		Roll 			& \SI{7}{°}					\\ \hline
	\end{tabular} 
	\vspace*{-3mm}
\end{table}

Die Erfolgsquote der Annäherung der wahren Systempose berechnet sich aus dem Quotienten der fehlgeschlagenen und insgesamt durchgeführten Lokalisationen. Als fehlgeschlagen werden dabei alle Lokalisationen betrachtet, bei welchen einer der definierten Grenzwerte überschritten wurde. Die Ergebnisse sind zusammen mit der durchschnittlich für die globale Lokalisation benötigten Rechenzeit $\bar{t}$ in \tab{approx_time} aufgeführt.

\begin{table}[ht]
	\centering
	\caption{Ermittelte Erfolgsquote und benötigte Rechenzeit}
	\label{tab.approx_time}
	\vspace*{-3mm}
	\begin{tabular}[ht]{|l|r|r|}\hline
		\rowcolor{Snow2}
		Modell			& Erfolgsquote [$\%$]	&	Rechenzeit $\bar{t}$	 [s]	\\ \hline
		Raycasting		& 56,25					&	\SI{532,89}{}			\\ \hline		
		Endpoint			& 75					&	\SI{55,66}{}			\\ \hline
	\end{tabular} 
	\vspace*{-3mm}
\end{table}

\red[Erfolgsquote interpretieren\\]

Wie aus \tab{approx_time} darüber hinaus ersichtlich wird, beträgt die benötigte Rechenzeit des \red[Raycasting]-Modells fast das \SI{10}{}-fache der vom \red[Endpoint]-Model benötigten Zeit. 
\red[Zeit der Lokalisation auswerten\\]

\red[Fazit daraus ableiten, welches besser geeignet ist? oder erst im Fazit/Zusammenfassung?\\]


\red[Quadratischer Mittelwert QMW statt Root Mean Square RMS überall aktualisieren\\]


\red[Relokalisation bei globaler Lokalisation beschreiben. Besser später als Ergänzung um die lokale Lokalisation zu korrigieren!\\]

\section{Lokale Lokalisation}%Tracking/Kontinuierliche Lokalisation}
Die Genauigkeit der lokalen Lokalisation wird gesondert von der durch die globale Lokalisation bestimmten Pose betrachtet. Dazu wird ebenfalls das für die Untersuchung der globalen Lokalisation verwendete Markerfeld genutzt. Die wahre Pose des Systems kann so wie zuvor bestimmt und als Initialisierung der Lokalisation verwendet werden.\\

Die Bewertung der kontinuierlichen Lokalisation erfolgt für translatorische und rotatorische Veränderungen der Systempose. Alle Messungen werden dabei separat durchgeführt um eine Beeinflussung der Bewegungen untereinander zu vermeiden.\\

\subsection{Translatorische Bewegung}
Die translatorischen Bewegungen werden parallel (x-Achse der Kamera, y-Achse des Systems) und orthogonal (z-Achse der Kamera, x-Achse des Systems) zu der Betrachtungsebene durchgeführt. Die parallele Bewegung entlang der zweiten zur Ebene parallelen Achse (y-Achse der Kamera, z-Achse des Systems) wird nicht gesondert betrachtet, da diese äquivalent zu der Bewegung entlang der ersten ist. \abb{fig.transmove} verdeutlicht dies und zeigt die Durchführung der Untersuchungen anhand eines beispielhaften Versuchsaufbaus.\\

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[scale=1.0]{spacer}
		\caption{Translatorische Bewegung}
		\label{fig.transmove}
	\end{center}
	%\vspace*{-8mm}
\end{figure}

Die quadratischen Mittelwerte der Lokalisationsfehler bei translatorischen Bewegungen parallel und orthogonal zur Betrachtungsebene sind in \abb{fig.loc_loc_trans} dargestellt.

\input{plot/loc_loc_trans}

\red[Ergebnisse interpretieren\\]
%\red[TransX und TransZ innerhalb vergleichen und Diagramme aufteilen nach translatorischem Fehler und rotatorischem Fehler?\\Oder direkt alles in einem -> 2x6 Balken!?]

\subsection{Rotatorische Bewegung}
\red[Vergleich zwischen Fovis und Fovis+IMU direkt zusammen in Diagramm aufführen? Erstmal nur Fovis würde dazu dienen, die Bewegungen untereinander zu vergleichen, aber was für Erkenntnisse erhält man daraus? Nick schlechter als Roll ; Nick durch IMU verbessert? -> Kompass sinnvoll! Dann evtl. aber ruhig auch Gierwinkelbewegung aufführen!\\]
Die Lokalisation während der Rotationsbewegungen wird zunächst allein auf Basis der visuellen Odometrie durchgeführt. Um die Fusion der Sensordaten mit den Daten der inertialen Messeinheit zu bewerten erfolgt anschließend ein Vergleich mit der Lokalisation auf Basis des Erweiterten Kalman Filters.\\
\red[Analog zur Auswertung der translatorischen Bewegungen werden lediglich die resultierenden Fehler aus den Rotationen um die Roll- und Nickachse ausgewertet. Die Rotation des Systems um die Gier-Achse unterscheidet sich für den Algorithmus der visuellen Odometrie nicht von der Rotation um die Nickachse, weshalb keine gesonderte Betrachtung durchgeführt wird.] Die Versuchsdurchführung der Bewegungen zur Bewertung der rotatorischen Fehlereinflüsse zeigt \abb{fig.rotmove}\\
\red[ypr alle aufführen oder nur roll und pitch, da yaw äquivalent zu pitch ist!? s.o.\\]

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[scale=1.0]{spacer}
		\caption{Rotatorische Bewegung}
		\label{fig.rotmove}
	\end{center}
	%\vspace*{-8mm}
\end{figure}

\red[Bilder des Aufbaus als subfigures!]

\subsubsection{Visuelle Odometrie}
Die aus den rotatorischen Bewegungen resultierenden Fehler in der ermittelten Systempose zeigt \abb{fig.loc_loc_rot_fovis_roll} für die Rotation um die Roll- und \abb{fig.loc_loc_rot_fovis_pitch} für die Rotation um die Nickachse.

\input{plot/loc_loc_rot_fovis}

\red[Ergebnisse interpretieren\\]

\subsubsection{Erweitertes Kalman-Filter}
\input{plot/loc_loc_rot_ekf_roll}

\input{plot/loc_loc_rot_ekf_pitch}

\red[Ergebnisse interpretieren\\]

%\subsection{Rotation Roll IMU+KALMAN}

\section{Projektionsgenauigkeit}
Die Genauigkeit der Projektion virtueller Modelldaten wird unter Verwendung einer externen Kamera durchgeführt. Diese wird zunächst analog zum Vorgehen für die RGB-Kamera des Kinect Sensors kalibriert (siehe \kapitel{chap.calib}), wodurch eine objektive Betrachtung der Projektionsgenauigkeit ermöglicht wird. Für die Untersuchung wird ein Markerfeld auf einer ebenen Unterlage fixiert und im Sicht- und Projektionsfeld des \kps{s} platziert. Das Markerfeld wird mittels der RGB-Kamera erfasst um die Transformation des \kps{s} relativ zum Markerfeld zu bestimmen.\\

Die bekannte Transformation zwischen Kamera- und Projektorkoordinaten ermöglicht daraufhin die Zuordnung der detektierten 3D-Koordinaten des Markerfeldes zu den 2D-Koordinaten des Projektorbildes. Um die Projektionsgenauigkeit zu überprüfen wird mittels des Projektors ein weiteres Markerfeld projiziert, welches bezogen auf die Projektorkoordinaten deckungsgleich mit dem realen Markerfeld ist. \red[\abb{fig.arprojected}]\\
\red[Umweg über Modellumgebung beschreiben?\\]

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[scale=0.5]{board_eval_cropped}
		\caption{AR Marker real und projiziert}
		\label{fig.arprojected}
	\end{center}
	%\vspace*{-8mm}
\end{figure}

Die externe Kamera wird nun eingesetzt, um beide Markerfelder gleichzeitig zu erfassen und die Abweichungen zwischen den Feldern bezüglich Position und Orientierung zu bestimmen. Dabei werden die Positionierungen sowohl des \kps{s} als auch der externen Kamera während der Untersuchungen variiert. Der gesamte Aufbau der durchgeführten Untersuchung ist in \abb{fig.projsetup} dargestellt.

\begin{figure}[!ht]
	\begin{center}
		\includegraphics[scale=1.0]{spacer}
		\caption{Aufbau zur Überprüfung der Projektionsgenauigkeit}
		\label{fig.projsetup}
	\end{center}
	%\vspace*{-8mm}
\end{figure}

\red[Die Ergebnisse der $n=6$ Messreihen sind als Box-Whisker-Plot in \abb{fig.boxplot_proj} dargestellt.]

\input{plot/projection}

\red[Öffnungswinkel $\sim$ 30°, dadurch Faktor 16/9 für Fehlerwerte in z-Richtung. Sogar (16/9)²!! für Detektion+Projektion? Dann würden sich die Werte auf jeden Fall stark annähern\\Bereinigtes Diagramm zeigen? welchen Nutzen?\\]

\red[Nennen, dass Boxplot ganze Messreihe abbildet! Oder umwandeln zu 5/95 Perzentil?\\]

%\section{Benutzerinteraktion}

%\input{plot/tests}
